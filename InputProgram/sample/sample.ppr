# Simple program for text classification, illustrating how to attach a
# classifier to a ProPPR rule.

# Pick a label Y for X, and decide if it's a good classification by
# calling ab_classify.


# "abduce" (i.e., guess at) a classification Y for document X. The
# antecedent of the rule is empty, so it always succeeds, but the
# weight for this rule will be based on features generated by the
# annotation { f(W,Y): hasWord(X,W) } -- ie, the words in document X
# will be paired with a label, and used as features.  Note that the
# weight of this rule will compete with the weight of the implicit
# 'reset' rule.

# old version, which doesn't use word weights
# ab_classify(X,Y) :- { f(W,Y): hasWord(X,W) }.

################ actual  #####################
# predict(X,Y) :- isLabel(Y), ab_classify(X,Y).
# ab_classify(X,Y) :- { f(Word,Y,Weight): hasWord(X,Word,Weight) }.


predict(X,Y) :- isLabel(Y), ab_classify(X,Y).
ab_classify(X,Y) :- { f(Word,Y): hasWord(X,Word) }.

################ Try This First ############
# predict(X,Y) :- isLabel(Y), ab_classify(X,Y).
# ab_classify(X,Y).

################ parse example ###############

# predict(X,Y) :- isLabel(Y), ab_classify(X,Y).
# ab_classify(X,Y) :- { f#(Word,Y,Weight): hasWord#(X,Word,Weight) }.
# predict(X,Y) :- isLabel(Y), ab_classify(X,Y)  #rel(Y)
# predict(X,Y) :- isLabel(Y), ab_classify(X,Y)  #rel(Y)